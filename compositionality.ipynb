{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compositionality.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2or7QGTv75r",
        "colab_type": "text"
      },
      "source": [
        "# LET's Test Compositionality\n",
        "\n",
        "Michael Neely & Leila Talha\n",
        "\n",
        "Natural Language Processing 2, Spring 2020\n",
        "\n",
        "University of Amsterdam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8mxa9NMHp4h",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "In many Natural Language Processing (NLP) tasks, data-driven deep learning models have proven more effective than their traditional, symbolic counterparts. Neural networks can process large amounts of data and are therefore more robust to the intrinsic noise of natural language. However, does their success on isolated tasks mean they genuinely understand the languages they are processing? Or perhaps, are they just exploiting statistical patterns?\n",
        "        \n",
        "The principle of compositionality is a fundamental feature of natural language and serves as a rigorous test of the robustness of a model's learned representation. In its most broad definition, compositionality refers to \"the meaning of a whole is a function of the meanings of the parts and of the way they are syntactically combined\" ([Kamp and Partee, 1995](https://doi.org/10.1016/0010-0277(94)00659-9)). Note that this statement only refers to language itself, not the behavior of an entity using the language. To address this gap, ([Hupkes et al. 2019](https://arxiv.org/abs/1908.08351)) propose a suite of behavioral tests designed to evaluate the compositionality of a neural model across five dimensions. Of the five aspects, systematicity --- whether models systematically recombine known parts and rules --- and localism --- whether models' composition operations are local or global --- are of particular note.\n",
        "\n",
        "In this research, we evaluate the compositionality of recurrent and attention-based neural models in terms of both localism and systematicity in the context of a sequence-to-sequence machine translation task on an artificial compositional language, which we call PFCG-LET. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW6jrh1ZhdlI",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iR56N2ud5N_",
        "colab_type": "text"
      },
      "source": [
        "### <a name=\"install\"></a> Install Dependencies\n",
        "\n",
        "**Warning: The runtime must be restarted to import OpenNMT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWllHF2FoNOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-py.git\n",
        "%cd OpenNMT-py\n",
        "!python setup.py install\n",
        "%cd ..\n",
        "!pip install torchtext==0.4.0 treelib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLtgOQt7R9GO",
        "colab_type": "text"
      },
      "source": [
        "### Optional: mount Google Drive storage for persistence\n",
        "\n",
        "Ensure you have a folder in the root of your drive named `pcfglet`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7FVkHW-QuuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqzZPE9NY_61",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uiiljnv-vbaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standard library\n",
        "import argparse\n",
        "from collections import Counter, defaultdict, OrderedDict\n",
        "import glob\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, Dict, List, Tuple, Union\n",
        "import uuid\n",
        "\n",
        "# external libraries\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import tight_layout\n",
        "import numpy as np\n",
        "import onmt\n",
        "import onmt.opts\n",
        "import onmt.translate\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import treelib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy0aNrTllNtL",
        "colab_type": "text"
      },
      "source": [
        "### Optional: load existing datasets and models from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5OeONVUlOmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r \"drive/My Drive/pcfglet/\" ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo5Yl8tUf2d0",
        "colab_type": "text"
      },
      "source": [
        "## PCFG List-Edit-Task (PCFG-LET)\n",
        "\n",
        "It is common practice to evaluate the compositionality of neural models in isolation by carefully designing artificial languages which exhibit desirable compositional phenomena. In theory, by controlling the training data in this manner, models should only be able to successfully generalize if they have formed an appropriate compositional representation or strategy.\n",
        "\n",
        "Like ([Hupkes et al. 2019](https://arxiv.org/abs/1908.08351)), the input alphabet of PCFG-LET consists of four categories of words: numerical characters which define a list, unary and binary functions which manipulate those lists, a comma (,) which separates binary arguments, and a special symbol \\texttt{E} that represents an empty list. These words are combined to generate input sequences that define a series of operations applied to the list argument(s). Note that the empty token can only appear in intermediate or output sequences.\n",
        "\n",
        "The task for a particular network is then to translate inputs into interpreted outputs by recursively applying the interpretation functions. Success should only be possible if networks are **local** in their operation and **systematic** in their approach since the functions are highly sensitive to the order of lists and arguments. The functions of the list-edit-task prevent sequence explosion, the phenomenon in which applications of interpretation functions lead to excessively long sequences. ([Hupkes et al. 2019](https://arxiv.org/abs/1908.08351)) highlight this as an unfortunate side-effect of their PCFG-SET."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGxGaX97wCVL",
        "colab_type": "text"
      },
      "source": [
        "### Define PCFG-LET as code\n",
        "\n",
        "Input alphabet and interpretation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkntb12Xv6vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "`# numbers from 1 to 519 (inclusive)\n",
        "VOCAB = list(range(1,520))\n",
        "\n",
        "# some operations may produce empty lists. Introduce a token to represent this\n",
        "EMPTY_TOKEN = 'E'\n",
        "\n",
        "# global that determines whether the empty token is included in input-sequences.\n",
        "# set to True if testing for systematicity.\n",
        "INCLUDE_EMPTY_TOKEN = False\n",
        "\n",
        "# Type: a token will either be an empty token (E), argument separator (,), function name, or vocabulary character\n",
        "Token = str\n",
        "\n",
        "# Type: a parsed token will either be an empty token (E), argument separator (,), unary function, binary function, or list of integers\n",
        "ParsedToken = Union[str, Callable, List[int]]\n",
        "\n",
        "####################\n",
        "# helper functions #\n",
        "####################\n",
        "\n",
        "def list_to_string(lst: List[Any]) -> str:\n",
        "  '''Convert a list to space-separated string'''\n",
        "  return ' '.join(map(str, lst))\n",
        "\n",
        "def split_list(given_list: List[Any], segments: int = 1) -> List[Any]:\n",
        "  '''Given a list, split into the defined number of segments'''\n",
        "  length = len(given_list)\n",
        "  return [ given_list[i*length // segments: (i+1)*length // segments] for i in range(segments) ]\n",
        "\n",
        "def is_valid_pcfg_function_name(name: str) -> bool:\n",
        "  '''Test if a given string is a valid PCFG-LET unary or binary function'''\n",
        "  return isinstance(name, str) and (hasattr(UnaryFunctions, name) or hasattr(BinaryFunctions, name))\n",
        "\n",
        "##############################################\n",
        "# PCFG-LET Unary (single-argument) functions #\n",
        "##############################################\n",
        "class UnaryFunctions:\n",
        "\n",
        "  @staticmethod\n",
        "  def min(fn_input: ParsedToken) -> ParsedToken:\n",
        "    '''Return the lowest character in the list'''\n",
        "    fn_input = list(filter(lambda elem: elem != EMPTY_TOKEN, fn_input))\n",
        "    if fn_input == EMPTY_TOKEN or fn_input == []:\n",
        "      return EMPTY_TOKEN\n",
        "    return [min(fn_input)]\n",
        "\n",
        "  @staticmethod\n",
        "  def max(fn_input: ParsedToken) -> ParsedToken:\n",
        "    '''Return the highest character in the list'''\n",
        "    fn_input = list(filter(lambda elem: elem != EMPTY_TOKEN, fn_input))\n",
        "    if fn_input == EMPTY_TOKEN or fn_input == []:\n",
        "      return EMPTY_TOKEN\n",
        "    return [max(fn_input)]\n",
        "\n",
        "  @staticmethod\n",
        "  def unique(fn_input: ParsedToken) -> ParsedToken:\n",
        "    '''Remove duplicate occurences of characters'''\n",
        "    if fn_input == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    fn_input = list(filter(lambda elem: elem != EMPTY_TOKEN, fn_input))\n",
        "    return list(OrderedDict.fromkeys(fn_input))\n",
        "\n",
        "  @staticmethod\n",
        "  def remove_unique(fn_input: ParsedToken) -> ParsedToken:\n",
        "    '''Remove characters that do not occur at least twice'''\n",
        "    if fn_input == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    fn_input = list(filter(lambda elem: elem != EMPTY_TOKEN, fn_input))\n",
        "    counts = Counter(fn_input)\n",
        "    out = [idx for idx, count in counts.items() if count != 1]\n",
        "    return out or EMPTY_TOKEN\n",
        "  \n",
        "  @staticmethod\n",
        "  def remove_repeated(fn_input: ParsedToken) -> ParsedToken:\n",
        "    '''Remove all occurences of characters that occur more than once'''\n",
        "    if fn_input == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    fn_input = list(filter(lambda elem: elem != EMPTY_TOKEN, fn_input))\n",
        "    counts = Counter(fn_input)\n",
        "    out = [idx for idx, count in counts.items() if count == 1]\n",
        "    return out or EMPTY_TOKEN\n",
        "\n",
        "  @staticmethod\n",
        "  def mirror(fn_input: ParsedToken) -> ParsedToken:\n",
        "    '''Rotate list 180 degrees'''\n",
        "    if fn_input == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    fn_input = list(filter(lambda elem: elem != EMPTY_TOKEN, fn_input))\n",
        "    a, b = split_list(fn_input, segments=2)\n",
        "    if len(fn_input) % 2 == 0:\n",
        "      return b + a\n",
        "    else:\n",
        "      return b[1:] + [b[0]] + a\n",
        "\n",
        "############################################\n",
        "# PCFG-LET Binary (two-argument) functions #\n",
        "############################################\n",
        "class BinaryFunctions():\n",
        "\n",
        "  @staticmethod\n",
        "  def filter(x: ParsedToken, y: ParsedToken) -> ParsedToken:\n",
        "    '''Order-sensitive: return all characters in x that do not occur in y'''\n",
        "    if x == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    elif y == EMPTY_TOKEN:\n",
        "      return x\n",
        "    elif x == EMPTY_TOKEN and y == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    else:\n",
        "      x = list(filter(lambda elem: elem != EMPTY_TOKEN, x))\n",
        "      filtered = [elem for elem in x if elem not in y]\n",
        "      return filtered or EMPTY_TOKEN\n",
        "\n",
        "  @staticmethod\n",
        "  def union(x: ParsedToken, y: ParsedToken) -> ParsedToken:\n",
        "    '''Symmetric: return unique characters that occur in x or y'''\n",
        "    if x == EMPTY_TOKEN:\n",
        "      return y\n",
        "    if y == EMPTY_TOKEN:\n",
        "      return x\n",
        "    if x == EMPTY_TOKEN and y == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    unique_to_y = [elem for elem in y if elem not in x]\n",
        "    return UnaryFunctions.unique(x + unique_to_y)\n",
        "\n",
        "  @staticmethod\n",
        "  def intersection(x: ParsedToken, y:ParsedToken) -> ParsedToken:\n",
        "    '''Symmetric: return unique characters that occur in both x and y'''\n",
        "    if x == EMPTY_TOKEN:\n",
        "      return y\n",
        "    if y == EMPTY_TOKEN:\n",
        "      return x\n",
        "    if x == EMPTY_TOKEN and y == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    x_in_y = [elem for elem in x if elem in y]\n",
        "    y_in_x = [elem for elem in y if elem in x]\n",
        "    combined = x_in_y + y_in_x\n",
        "    return UnaryFunctions.unique(x_in_y + y_in_x) if combined else EMPTY_TOKEN\n",
        "\n",
        "  @staticmethod\n",
        "  def difference(x: ParsedToken, y:ParsedToken) -> ParsedToken:\n",
        "    '''Symmetric: return the unique disjunctive union of x and y'''\n",
        "    unique_to_x = BinaryFunctions.filter(x, y)\n",
        "    unique_to_y = BinaryFunctions.filter(y, x)\n",
        "    if unique_to_x == EMPTY_TOKEN and unique_to_y != EMPTY_TOKEN:\n",
        "      return unique_to_y\n",
        "    elif unique_to_y == EMPTY_TOKEN and unique_to_x != EMPTY_TOKEN:\n",
        "      return unique_to_x\n",
        "    elif unique_to_x == EMPTY_TOKEN and unique_to_y == EMPTY_TOKEN:\n",
        "      return EMPTY_TOKEN\n",
        "    return UnaryFunctions.unique(unique_to_x + unique_to_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egVTATpS9MDn",
        "colab_type": "text"
      },
      "source": [
        "### Define functions to generate PCFG-LET commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O1RoS_4Av1JZ",
        "colab": {}
      },
      "source": [
        "###### The CFG ######\n",
        "\n",
        "## Non-terminal rules:\n",
        "# S --> Fu S | Fb S, S\n",
        "# S --> X              \n",
        "# X --> X X           \n",
        "\n",
        "## Lexical rules:\n",
        "# Fu --> min | max | unique | remove unique | remove duplicates | mirror\n",
        "# Fb --> filter | union | intersection | difference \n",
        "# X --> 1 | 2 | ... | 518 | 519\n",
        "\n",
        "#####################\n",
        "\n",
        "Fu = {'min':.2,'max':.2, 'remove_unique':.2,'remove_repeated':.2, 'mirror':.2}\n",
        "Fb = {'filter':.25, 'union':.25, 'intersection':.25, 'difference':.25}\n",
        "\n",
        "\n",
        "def S_rule(command):\n",
        "  '''Performs one of the S --> . rules from the PCFG, with probabilities [.6, .4]'''  \n",
        "  if command == []:\n",
        "\n",
        "    start = np.random.choice([Fu, Fb])\n",
        "    func_name = np.random.choice(list(start.keys()), p=list(start.values()))\n",
        "    if start == Fu:\n",
        "      return [func_name, S_rule(['S'])]\n",
        "    else:\n",
        "      return [func_name, S_rule(['S']), ',', S_rule(['S'])]\n",
        "  \n",
        "  else:\n",
        "\n",
        "    next_rule = np.random.choice(['S', 'X'], p=[.6, .4])\n",
        "    if next_rule == 'S':\n",
        "      return S_rule([])\n",
        "    else:\n",
        "      return X_rule(['X'])\n",
        "\n",
        "\n",
        "def X_rule(command):\n",
        "  '''Performs one of the X --> . rules from the PCFG, with probabilities [.45, .55]'''\n",
        "  while 'X' in command:\n",
        "\n",
        "    idx_1st_X = command.index('X')\n",
        "    next_rule = np.random.choice(['X X', 'X'], p=[.45,.55])\n",
        "\n",
        "    if next_rule == 'X X':\n",
        "      command.insert(idx_1st_X, 'X')\n",
        "      return (X_rule(command))\n",
        "    else:\n",
        "      if INCLUDE_EMPTY_TOKEN:\n",
        "        symbol = np.random.choice([EMPTY_TOKEN] + VOCAB)\n",
        "        if symbol != EMPTY_TOKEN: symbol = int(symbol)\n",
        "      else:\n",
        "        symbol = int(np.random.choice(VOCAB))\n",
        "      command[idx_1st_X] = symbol\n",
        "    \n",
        "  return command\n",
        "\n",
        "\n",
        "def compute_output(command):\n",
        "  '''Computes the output of a command, given as a nested list'''\n",
        "  while isinstance(command, list) and \\\n",
        "  not all(isinstance(x,np.int) or x==EMPTY_TOKEN for x in command):\n",
        "    \n",
        "    func_name = command[0]\n",
        "    S1 = compute_output(command[1])\n",
        "\n",
        "    if func_name in list(Fu.keys()):\n",
        "      return getattr(UnaryFunctions, func_name)(S1)\n",
        "    else:\n",
        "      S2 = compute_output(command[3])\n",
        "\n",
        "      return getattr(BinaryFunctions, func_name)(S1, S2)\n",
        "\n",
        "  return command\n",
        "\n",
        "# Used for localism analysis\n",
        "def recurse_unroll(command: List[Any], wildcards: List[str], steps: List[Any]) -> None:\n",
        "  '''Side-effect function only used by get_unrolled_steps'''\n",
        "  while isinstance(command, list) and not all(isinstance(x,np.int) for x in command):\n",
        "    func_name = command[0]\n",
        "    S1 = recurse_unroll(command[1], wildcards, steps)\n",
        "    S1 = list_to_string(S1) if isinstance(S1, list) else S1\n",
        "    if func_name in list(Fu.keys()):\n",
        "      next_wildcard = wildcards.pop()\n",
        "      steps.append(f'{func_name} {S1}|{next_wildcard}')\n",
        "    else:\n",
        "      S2 = recurse_unroll(command[3], wildcards, steps)\n",
        "      S2 = list_to_string(S2) if isinstance(S2, list) else S2\n",
        "      next_wildcard = wildcards.pop()\n",
        "      steps.append(f'{func_name} {S1} , {S2}|{next_wildcard}')\n",
        "    return next_wildcard\n",
        "  return command\n",
        "\n",
        "def get_unrolled_steps(raw_command: List[Any], str_command: str) -> List[str]:\n",
        "  '''Given a raw command and its string version, return a list of the unrolled steps required to solve the command recursively\n",
        "     e.g. difference remove_unique min 17 , 23 --> ['min 17|*1', 'remove_unique *1|*2', 'difference *2 , 23|*3']'''\n",
        "  num_functions = sum([is_valid_pcfg_function_name(x) for x in str_command.split(' ')])\n",
        "  wildcards = list(reversed([f'*{i}' for i in range(1, num_functions + 1)]))\n",
        "  unrolled_steps = []\n",
        "  recurse_unroll(raw_command, wildcards, unrolled_steps)\n",
        "  return unrolled_steps\n",
        "\n",
        "\n",
        "def depth(l):\n",
        "  '''Recursively compute depth of nested list\n",
        "     source: https://stackoverflow.com/questions/6039103/counting-depth-or-the-deepest-level-a-nested-list-goes-to'''\n",
        "  if isinstance(l, list):\n",
        "      return 1 + max(depth(item) for item in l)\n",
        "  else:\n",
        "      return 0\n",
        "\n",
        "def flatten(A):\n",
        "  '''Flattens a list of strings and list, source:\n",
        "     https://stackoverflow.com/questions/17864466/flatten-a-list-of-strings-and-lists-of-strings-and-lists-in-python'''\n",
        "  rt = []\n",
        "  for i in A:\n",
        "    if isinstance(i,list): rt.extend(flatten(i))\n",
        "    else: rt.append(i)\n",
        "\n",
        "  return rt\n",
        "\n",
        "\n",
        "def generate_command() -> Tuple[str, int, List[str], List[str]]:\n",
        "  '''Returns a new command as a string, along with its depth, output, and unrolled steps'''\n",
        "  raw_command = S_rule([])\n",
        "  command = ' '.join([str(x) for x in flatten(raw_command)])\n",
        "  # recursive depth function over-reports by 1 e.g. ['max', 1] == depth of 2\n",
        "  command_depth = depth(raw_command) - 1 \n",
        "  output = compute_output(raw_command)\n",
        "  unrolled_steps = get_unrolled_steps(raw_command, command)\n",
        "\n",
        "  return command, command_depth, output, unrolled_steps\n",
        "\n",
        "\n",
        "# Samples n commands from the PCFG\n",
        "def get_commands(n):\n",
        "  for _ in range(n):\n",
        "    yield generate_command()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKqMm3PchqAw",
        "colab_type": "text"
      },
      "source": [
        "### Generate some sample commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mq0k-UBhn6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for command in get_commands(10):\n",
        "  command_string, command_depth, output, unrolled_steps = command\n",
        "  print(f'Command: {command_string}\\nDepth: {command_depth}\\nOutput: {output}\\nUnrolled Steps: {unrolled_steps}\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBoBhiOri-VD",
        "colab_type": "text"
      },
      "source": [
        "## Generate Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T04eVOp8PpZX",
        "colab_type": "text"
      },
      "source": [
        "We create a dataset of 100,000 (one-hundred-thousand) input-output pairs by sampling from the grammar. To eliminate any possibility of memorization, we ensure each sample is unique. By unique, we mean that the arguments to any given function are **never repeated**. We do **not** perform any form of naturalization, and do **not** limit the length of list arguments given to the functions, but do cap sequence length to 50 (fifty) tokens for performance. Data is split into portions of 85\\%, 5\\%, and 10\\% for training, validation, and testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTfiUgasjma-",
        "colab_type": "text"
      },
      "source": [
        "### Define dataset generation code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rgmy7CPjlLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensure_dir(file_path: str) -> None:\n",
        "  '''Create a directory at the provided path if one does not already exist'''\n",
        "  directory = os.path.dirname(file_path)\n",
        "  if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "def load_dataset_frames() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "  '''Load train, test, validation, and full dataset from the persistence folder'''\n",
        "  train = pd.read_pickle('pcfglet/train.pkl')\n",
        "  val = pd.read_pickle('pcfglet/val.pkl')\n",
        "  test = pd.read_pickle('pcfglet/test.pkl')\n",
        "  full_set = pd.read_pickle('pcfglet/all.pkl')\n",
        "  return train, test, val, full_set\n",
        "\n",
        "def generate_dataset(n_samples: int = 100000, ratios: List[float] = [0.85, 0.05, 0.1]) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "  '''Builds a full dataset of the given number of samples and splits it into sets per the given ratios'''\n",
        "  assert sum(ratios) == 1, \"split-ratios do not sum to 1.\"\n",
        "\n",
        "  ensure_dir('pcfglet/')\n",
        "\n",
        "  # generate unique samples: make sure that the function arguments are never repeated\n",
        "  seen_arguments = {k: defaultdict() for k in list(Fu.keys()) + list(Fb.keys())}\n",
        "  columns = {'command': [], 'length': [],  'depth': [], 'num_functions': [], 'target': [], 'unrolled_steps': []}\n",
        "\n",
        "  with tqdm(total=n_samples) as pbar:\n",
        "    pbar.set_description('Unique commands generated:')\n",
        "    while len(columns['command']) < n_samples:\n",
        "      command_tuple = get_commands(1)\n",
        "      command, depth, target, unrolled_steps = next(command_tuple)\n",
        "      command_as_list = command.split(' ')\n",
        "      if len(command_as_list) > 50:\n",
        "        continue\n",
        "      is_duplicate = False\n",
        "      for idx, token in enumerate(command_as_list):\n",
        "        if is_valid_pcfg_function_name(token):\n",
        "          remaining_tokens = command_as_list[idx + 1:]\n",
        "          args = []\n",
        "          for remaining_token in remaining_tokens:\n",
        "            if is_valid_pcfg_function_name(remaining_token) or remaining_token == ',':\n",
        "              break\n",
        "            else:\n",
        "              args.append(remaining_token)\n",
        "          if len(args) > 0:\n",
        "            args = list_to_string(args)\n",
        "            found = seen_arguments[token].get(args)\n",
        "            if found:\n",
        "              is_duplicate = True\n",
        "              continue\n",
        "            else:\n",
        "              seen_arguments[token][args] = 1\n",
        "      if is_duplicate:\n",
        "        continue\n",
        "      pbar.update(1)\n",
        "      command_length = len(command_as_list)\n",
        "      num_functions = sum([is_valid_pcfg_function_name(tok) for tok in command_as_list])\n",
        "      target = list_to_string(target)\n",
        "      columns['command'].append(command)\n",
        "      columns['length'].append(command_length)\n",
        "      columns['depth'].append(depth)\n",
        "      columns['num_functions'].append(num_functions)\n",
        "      columns['target'].append(target)\n",
        "      columns['unrolled_steps'].append(unrolled_steps)\n",
        "\n",
        "  df = pd.DataFrame.from_records(columns)\n",
        "\n",
        "  # Raw dataframes for analysis\n",
        "  train, test, val = np.split(df.sample(frac=1), [int(ratios[0]*len(df)), int((1-ratios[1])*len(df))])\n",
        "  \n",
        "  train.to_pickle('pcfglet/train.pkl')\n",
        "  test.to_pickle('pcfglet/test.pkl')\n",
        "  val.to_pickle('pcfglet/val.pkl')\n",
        "  df.to_pickle('pcfglet/all.pkl')\n",
        "\n",
        "  # Commands and targets only for OpenNMT scripts\n",
        "  train.to_csv(f'pcfglet/src-train.txt', sep=';', columns=['command'], index=False, header=False, mode='w+')\n",
        "  train.to_csv(f'pcfglet/tgt-train.txt', sep=';', columns=['target'], index=False, header=False, mode='w+')\n",
        "  test.to_csv('pcfglet/src-test.txt', sep=';', columns=['command'], index=False, header=False, mode='w+')\n",
        "  test.to_csv('pcfglet/tgt-test.txt', sep=';', columns=['target'], index=False, header=False, mode='w+')\n",
        "  val.to_csv('pcfglet/src-val.txt', sep=';', columns=['command'], index=False, header=False, mode='w+')\n",
        "  val.to_csv('pcfglet/tgt-val.txt', sep=';', columns=['target'], index=False, header=False, mode='w+')\n",
        "\n",
        "  return train, test, val, df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sOoCF6vlglU",
        "colab_type": "text"
      },
      "source": [
        "### Generate a new dataset if one was not imported\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x67BZQvYlj7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_files = [\n",
        "  'pcfglet/train.pkl',\n",
        "  'pcfglet/val.pkl',\n",
        "  'pcfglet/test.pkl',\n",
        "  'pcfglet/all.pkl',\n",
        "  'pcfglet/src-train.txt',\n",
        "  'pcfglet/tgt-train.txt',\n",
        "  'pcfglet/src-val.txt',\n",
        "  'pcfglet/tgt-val.txt',\n",
        "  'pcfglet/src-test.txt',\n",
        "  'pcfglet/tgt-test.txt'\n",
        "]\n",
        "\n",
        "# generate a new dataset if all of the required files are not present\n",
        "if all([Path(f).is_file() for f in data_files]):\n",
        "  print('Dataset already exists. Loading from disk.')\n",
        "  TRAIN_SET, TEST_SET, VAL_SET, ALL = load_dataset_frames()\n",
        "else:\n",
        "  # Use same split as Hupkes et al. 2019\n",
        "  TRAIN_SET, TEST_SET, VAL_SET, ALL = generate_dataset()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2oug8ZWk8mE",
        "colab_type": "text"
      },
      "source": [
        "#### Confirm the dataset matches expectations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1RedcSDk70K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert ALL.command.is_unique\n",
        "assert TRAIN_SET.command.is_unique\n",
        "assert VAL_SET.command.is_unique\n",
        "assert TEST_SET.command.is_unique\n",
        "assert len(ALL) == 100000\n",
        "assert len(TRAIN_SET) == 85000\n",
        "assert len(VAL_SET) == 5000\n",
        "assert len(TEST_SET) == 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDE9_bTYJ7lF",
        "colab_type": "text"
      },
      "source": [
        "### Visualise dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjADbvhMJ5hM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_dataset_distribution(dataset: pd.DataFrame):\n",
        "  dist_plot = sns.jointplot(\n",
        "      x='depth',\n",
        "      y='length',\n",
        "      data=dataset,\n",
        "      kind=\"kde\",\n",
        "      xlim=(1,3),\n",
        "      ylim=(1,20),\n",
        "      space=0)\n",
        "  dist_plot.ax_joint.set_xticks([1,2,3])\n",
        "  dist_plot.ax_joint.set_yticks([2,10,20,])\n",
        "  plt.savefig('pcfglet/distribution_plot.png')\n",
        "\n",
        "if not Path('pcfglet/distribution_plot.png').is_file():\n",
        "  plot_dataset_distribution(ALL)\n",
        "else:\n",
        "  display(Image('pcfglet/distribution_plot.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wZI2COJ0XYf",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess data with OpenNMT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4GZ9Ud40XB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_files = [\n",
        "  'pcfglet/processed.train.0.pt',\n",
        "  'pcfglet/processed.valid.0.pt',\n",
        "  'pcfglet/processed.vocab.pt'\n",
        "]\n",
        "\n",
        "# no need to pre-process if the files were imported from Drive\n",
        "if not all([Path(f).is_file() for f in processed_files]):\n",
        "  !python OpenNMT-py/preprocess.py -train_src pcfglet/src-train.txt -train_tgt pcfglet/tgt-train.txt -valid_src pcfglet/src-val.txt -valid_tgt pcfglet/tgt-val.txt -save_data pcfglet/processed -src_seq_length 100 -tgt_seq_length 100 -overwrite -filter_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFEAtZL4tiAV",
        "colab_type": "text"
      },
      "source": [
        "### Optional Checkpoint: persist dataset and preprocessed files to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6RzBQi_tiqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r pcfglet/processed* \"drive/My Drive/pcfglet/\"\n",
        "# !cp -r pcfglet/*.pkl \"drive/My Drive/pcfglet/\"\n",
        "# !cp -r pcfglet/src-*.txt \"drive/My Drive/pcfglet/\"\n",
        "# !cp -r pcfglet/tgt-*.txt \"drive/My Drive/pcfglet/\"\n",
        "# !cp -r pcfglet/*.png \"drive/My Drive/pcfglet/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mTZ1LowkmIT",
        "colab_type": "text"
      },
      "source": [
        "## Train Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thnRsOYhRY5B",
        "colab_type": "text"
      },
      "source": [
        "Models examined in the literature tend to fall into three categories: recurrent, convolutional, or purely attention-based. Initial experimentation with convolutional models led to consistently poor results. Taking this as evidence of the order-sensitive nature of the task, we chose to study the other architectures.\n",
        "\n",
        "**Model 1: LSTMS2S**\n",
        "\n",
        "The sequential processing nature of LSTM models is ideal for PCFG-LET. We select a fully recurrent, bidirectional model with attention similar to the LSTMS2S architecture of ([Hupkes et al. 2019](https://arxiv.org/abs/1908.08351)). With careful hyperparameter tuning, we decide on a 512-dimensional word vector size with scaled dot-product attention ([Vaswani et al. 2019](https://arxiv.org/abs/1706.03762)) and a batch size of 64 sequences. We train the model for 25 epochs or until convergence (five successive epochs with no improvement in word accuracy and perplexity on the validation set), using the Adam optimizer with a standard learning rate of 0.001.\n",
        "\n",
        "**Model 2: Transformer**\n",
        "\n",
        "Transformers discard recurrent cells in favor of a purely attention-based approach. Such a design is advantageous for processing longer sequences. By inferring order from position encodings, the cost of relating tokens remains uniform regardless of their distance. Unlike LSTMs, additional stacked layers in a transformer improve hierarchical modeling capability. A drawback of the Transformer model is its sensitivity to hyperparameter tuning. We experimented with different settings, but ultimately found the set chosen by ([Hupkes et al. 2019](https://arxiv.org/abs/1908.08351)), to be optimal. The only difference between our Transformer Model and Hupkes et al. 's is a reduced word vector dimensionality of 256. The transformer model is trained for 25 epochs (or until convergence), similarly to the LSTMS2S."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EiqKb-zCI6K",
        "colab_type": "text"
      },
      "source": [
        "Define checkpoint manipulation code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbsSvtlpspu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model checkpoints are saved as {type}_{run id}_step_{stepnumber}.pt\n",
        "# e.g. \"lstms2s_1_step_6640.pt\"\n",
        "\n",
        "def get_checkpoint_files_in_dir(path: str) -> List[str]:\n",
        "  '''Find all OpenNMT model checkpoint files in a given directory'''\n",
        "  model_checkpoints = f'{path}/*_step_*.pt'\n",
        "  hits = glob.glob(model_checkpoints)\n",
        "  return hits\n",
        "\n",
        "def get_best_model_step_from_trace(trace_path: str) -> int:\n",
        "  '''Extract the best model step number from an OpenNMT training trace file'''\n",
        "  backup = None # return lastest model if training didn't converge\n",
        "  for line in reversed(list(open(trace_path, 'r'))):\n",
        "    stripped_line = line.rstrip()\n",
        "    if 'best model found' in stripped_line.lower():\n",
        "      return int(stripped_line.split(' ')[-1])\n",
        "    elif 'saving checkpoint' in stripped_line.lower():\n",
        "      backup = int(stripped_line.split('_')[-1].split('.')[0])\n",
        "  return backup\n",
        "\n",
        "def select_best_model(model_type: str, run_id: int) -> str:\n",
        "  '''Find the best performing OpenNMT model checkpoint file by analyzing the trace'''\n",
        "  best_step = get_best_model_step_from_trace(f'pcfglet/{model_type}_{run_id}_trace.txt')\n",
        "  best_model = None\n",
        "  deleted = 0\n",
        "  for hit in get_checkpoint_files_in_dir('pcfglet'):\n",
        "    _, checkpoint_file = os.path.split(hit)\n",
        "    file_name, _ = os.path.splitext(checkpoint_file)\n",
        "    found_model_type, found_run_id, _, found_step = file_name.split('_')\n",
        "    if found_model_type == model_type and int(found_run_id) == run_id:\n",
        "      if int(found_step) == best_step:\n",
        "        best_model = hit\n",
        "      else:\n",
        "        os.remove(hit)\n",
        "        deleted += 1\n",
        "  print(f'Removed {deleted} checkpoints')\n",
        "  return best_model\n",
        "\n",
        "def model_from_run_exists(path: str, model_type: str, run_id: int) -> bool:\n",
        "  '''Check if a model has already been trained for the given type and run id'''\n",
        "  for hit in get_checkpoint_files_in_dir(path):\n",
        "    _, checkpoint_file = os.path.split(hit)\n",
        "    name_segments = checkpoint_file.split('_')\n",
        "    if name_segments[0] == model_type and int(name_segments[1]) == run_id:\n",
        "      return True\n",
        "  return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a9BzKntuPUy",
        "colab_type": "text"
      },
      "source": [
        "### Train LSTMS2S\n",
        "\n",
        "Train an LSTM with specified setting, for 25 epochs or until convergence (word accuracy has not improved for five consecutive validation steps). The best model number from each trial is extracted from the trace files. Other checkpoints are deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKDcAWB8xqT1",
        "colab_type": "text"
      },
      "source": [
        "#### Trial 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjxN5piFT5Ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not model_from_run_exists('pcfglet', 'lstms2s', 1):\n",
        "  !python OpenNMT-py/train.py \\\n",
        "    -data pcfglet/processed \\\n",
        "    -save_model \"pcfglet/lstms2s_1\" \\\n",
        "    -word_vec_size 512 \\\n",
        "    -encoder_type brnn \\\n",
        "    -global_attention dot \\\n",
        "    -batch_size 64 \\\n",
        "    -optim adam \\\n",
        "    -learning_rate 0.001 \\\n",
        "    -train_steps 33200 \\\n",
        "    -valid_steps 1328 \\\n",
        "    -save_checkpoint_steps 1328 \\\n",
        "    -early_stopping 5 \\\n",
        "    -world_size 1 \\\n",
        "    -gpu_ranks 0 2>&1 | tee pcfglet/lstms2s_1_trace.txt\n",
        "    \n",
        "else:\n",
        "  print('A first run LSTM model has already been trained')\n",
        "\n",
        "BEST_LSTM_RUN_1 = select_best_model('lstms2s', 1)\n",
        "%env BEST_LSTM_RUN_1=$BEST_LSTM_RUN_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK2rY1Rgxsj_",
        "colab_type": "text"
      },
      "source": [
        "#### Trial 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er2TUqC9xfBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not model_from_run_exists('pcfglet', 'lstms2s', 2):\n",
        "  !python OpenNMT-py/train.py \\\n",
        "    -data pcfglet/processed \\\n",
        "    -save_model \"pcfglet/lstms2s_2\" \\\n",
        "    -word_vec_size 512 \\\n",
        "    -encoder_type brnn \\\n",
        "    -global_attention dot \\\n",
        "    -batch_size 64 \\\n",
        "    -optim adam \\\n",
        "    -learning_rate 0.001 \\\n",
        "    -train_steps 33200 \\\n",
        "    -valid_steps 1328 \\\n",
        "    -save_checkpoint_steps 1328 \\\n",
        "    -early_stopping 5 \\\n",
        "    -world_size 1 \\\n",
        "    -gpu_ranks 0 2>&1 | tee pcfglet/lstms2s_2_trace.txt\n",
        "    \n",
        "else:\n",
        "  print('A second run LSTM model has already been trained')\n",
        "\n",
        "\n",
        "BEST_LSTM_RUN_2 = select_best_model('lstms2s', 2)\n",
        "%env BEST_LSTM_RUN_2=$BEST_LSTM_RUN_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qtx2Spvxu0S",
        "colab_type": "text"
      },
      "source": [
        "#### Trial 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAPM5QWqxo4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not model_from_run_exists('pcfglet', 'lstms2s', 3):\n",
        "  !python OpenNMT-py/train.py \\\n",
        "    -data pcfglet/processed \\\n",
        "    -save_model \"pcfglet/lstms2s_3\" \\\n",
        "    -word_vec_size 512 \\\n",
        "    -encoder_type brnn \\\n",
        "    -global_attention dot \\\n",
        "    -batch_size 64 \\\n",
        "    -optim adam \\\n",
        "    -learning_rate 0.001 \\\n",
        "    -train_steps 33200 \\\n",
        "    -valid_steps 1328 \\\n",
        "    -save_checkpoint_steps 1328 \\\n",
        "    -early_stopping 5 \\\n",
        "    -world_size 1 \\\n",
        "    -gpu_ranks 0 2>&1 | tee pcfglet/lstms2s_3_trace.txt\n",
        "    \n",
        "else:\n",
        "  print('A third run LSTM model has already been trained')\n",
        "\n",
        "\n",
        "BEST_LSTM_RUN_3 = select_best_model('lstms2s', 3)\n",
        "%env BEST_LSTM_RUN_3=$BEST_LSTM_RUN_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfYbEejrxAcj",
        "colab_type": "text"
      },
      "source": [
        "#### Optional Checkpoint: persist trained LSTM models and traces to Drive\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFypW4GHtgJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r pcfglet/lstms2s_* \"drive/My Drive/pcfglet/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT6-u8AuHKYf",
        "colab_type": "text"
      },
      "source": [
        "#### Translate test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja95TppgHMlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not Path('pcfglet/pred_lstms2s_run_1.txt').is_file():\n",
        "  !python OpenNMT-py/translate.py \\\n",
        "  -model \"$BEST_LSTM_RUN_1\" \\\n",
        "  -src pcfglet/src-test.txt \\\n",
        "  -tgt pcfglet/tgt-test.txt \\\n",
        "  -output pcfglet/pred_lstms2s_run_1.txt\n",
        "\n",
        "if not Path('pcfglet/pred_lstms2s_run_3.txt').is_file():\n",
        "  !python OpenNMT-py/translate.py \\\n",
        "  -model \"$BEST_LSTM_RUN_2\" \\\n",
        "  -src pcfglet/src-test.txt \\\n",
        "  -tgt pcfglet/tgt-test.txt \\\n",
        "  -output pcfglet/pred_lstms2s_run_2.txt\n",
        "\n",
        "if not Path('pcfglet/pred_lstms2s_run_3.txt').is_file():\n",
        "  !python OpenNMT-py/translate.py \\\n",
        "  -model \"$BEST_LSTM_RUN_3\" \\\n",
        "  -src pcfglet/src-test.txt \\\n",
        "  -tgt pcfglet/tgt-test.txt \\\n",
        "  -output pcfglet/pred_lstms2s_run_3.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6eoM_N7XZMV",
        "colab_type": "text"
      },
      "source": [
        "#### Optional Checkpoint: persist Predictions to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAHdnS8jXdFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r pcfglet/pred_lstms2s_* \"drive/My Drive/pcfglet/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjo6eBmFuR_m",
        "colab_type": "text"
      },
      "source": [
        "### Train Transformer\n",
        "\n",
        "Train a transformer with specified setting, for approximately 25 epochs or until convergence (word accuracy has not improved for five consecutive validation steps). The best model number from each trial is extracted from the trace files. Other checkpoints are deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQeG8lXkF0hR",
        "colab_type": "text"
      },
      "source": [
        "#### Trial 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf5JIeDhuTNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not model_from_run_exists('pcfglet', 'transformer', 1):\n",
        "  !python OpenNMT-py/train.py \\\n",
        "    -data pcfglet/processed \\\n",
        "    -save_model \"pcfglet/transformer_1\"  \\\n",
        "    -layers 6 \\\n",
        "    -rnn_size 256 \\\n",
        "    -word_vec_size 256 \\\n",
        "    -transformer_ff 2048 \\\n",
        "    -heads 8  \\\n",
        "    -encoder_type transformer \\\n",
        "    -decoder_type transformer \\\n",
        "    -position_encoding \\\n",
        "    -train_steps 33200 \\\n",
        "    -max_generator_batches 2 \\\n",
        "    -dropout 0.1 \\\n",
        "    -batch_size 64 \\\n",
        "    -accum_count 2 \\\n",
        "    -optim adam \\\n",
        "    -adam_beta2 0.998 \\\n",
        "    -decay_method noam \\\n",
        "    -warmup_steps 8000 \\\n",
        "    -learning_rate 1 \\\n",
        "    -max_grad_norm 0 \\\n",
        "    -param_init 0 \\\n",
        "    -param_init_glorot \\\n",
        "    -valid_steps 1328 \\\n",
        "    -early_stopping 5 \\\n",
        "    -save_checkpoint_steps 1328 \\\n",
        "    -world_size 1 \\\n",
        "    -gpu_ranks 0 2>&1 | tee pcfglet/transformer_1_trace.txt\n",
        "else:\n",
        "  print('A first run Transformer model has already been trained')\n",
        "\n",
        "BEST_TRANSFORMER_RUN_1 = select_best_model('transformer', 1)\n",
        "%env BEST_TRANSFORMER_RUN_1=$BEST_TRANSFORMER_RUN_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FimUqQDFGgIM",
        "colab_type": "text"
      },
      "source": [
        "#### Trial 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO5gWOgBGhON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not model_from_run_exists('pcfglet', 'transformer', 2):\n",
        "  !python OpenNMT-py/train.py \\\n",
        "    -data pcfglet/processed \\\n",
        "    -save_model \"pcfglet/transformer_2\"  \\\n",
        "    -layers 6 \\\n",
        "    -rnn_size 256 \\\n",
        "    -word_vec_size 256 \\\n",
        "    -transformer_ff 2048 \\\n",
        "    -heads 8  \\\n",
        "    -encoder_type transformer \\\n",
        "    -decoder_type transformer \\\n",
        "    -position_encoding \\\n",
        "    -train_steps 33200 \\\n",
        "    -max_generator_batches 2 \\\n",
        "    -dropout 0.1 \\\n",
        "    -batch_size 64 \\\n",
        "    -accum_count 2 \\\n",
        "    -optim adam \\\n",
        "    -adam_beta2 0.998 \\\n",
        "    -decay_method noam \\\n",
        "    -warmup_steps 8000 \\\n",
        "    -learning_rate 1 \\\n",
        "    -max_grad_norm 0 \\\n",
        "    -param_init 0 \\\n",
        "    -param_init_glorot \\\n",
        "    -valid_steps 1328 \\\n",
        "    -early_stopping 5 \\\n",
        "    -save_checkpoint_steps 1328 \\\n",
        "    -world_size 1 \\\n",
        "    -gpu_ranks 0 2>&1 | tee pcfglet/transformer_2_trace.txt\n",
        "else:\n",
        "  print('A second run Transformer model has already been trained')\n",
        "\n",
        "\n",
        "BEST_TRANSFORMER_RUN_2 = select_best_model('transformer', 2)\n",
        "%env BEST_TRANSFORMER_RUN_2=$BEST_TRANSFORMER_RUN_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w_H8aSvGifq",
        "colab_type": "text"
      },
      "source": [
        "#### Trial 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5tSse_rGjbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not model_from_run_exists('pcfglet', 'transformer', 3):\n",
        "  !python OpenNMT-py/train.py \\\n",
        "    -data pcfglet/processed \\\n",
        "    -save_model \"pcfglet/transformer_3\"  \\\n",
        "    -layers 6 \\\n",
        "    -rnn_size 256 \\\n",
        "    -word_vec_size 256 \\\n",
        "    -transformer_ff 2048 \\\n",
        "    -heads 8  \\\n",
        "    -encoder_type transformer \\\n",
        "    -decoder_type transformer \\\n",
        "    -position_encoding \\\n",
        "    -train_steps 33200 \\\n",
        "    -max_generator_batches 2 \\\n",
        "    -dropout 0.1 \\\n",
        "    -batch_size 64 \\\n",
        "    -accum_count 2 \\\n",
        "    -optim adam \\\n",
        "    -adam_beta2 0.998 \\\n",
        "    -decay_method noam \\\n",
        "    -warmup_steps 8000 \\\n",
        "    -learning_rate 1 \\\n",
        "    -max_grad_norm 0 \\\n",
        "    -param_init 0 \\\n",
        "    -param_init_glorot \\\n",
        "    -valid_steps 1328 \\\n",
        "    -early_stopping 5 \\\n",
        "    -save_checkpoint_steps 1328 \\\n",
        "    -world_size 1 \\\n",
        "    -gpu_ranks 0 2>&1 | tee pcfglet/transformer_3_trace.txt\n",
        "else:\n",
        "  print('A third run Transformer model has already been trained')\n",
        "\n",
        "BEST_TRANSFORMER_RUN_3 = select_best_model('transformer', 3)\n",
        "%env BEST_TRANSFORMER_RUN_3=$BEST_TRANSFORMER_RUN_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4cPGIKiSYU7",
        "colab_type": "text"
      },
      "source": [
        "#### Optional Checkpoint: persist trained Transformer models and traces to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7wW7xdvSxI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r pcfglet/transformer_* \"drive/My Drive/pcfglet/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT2MABaccSSP",
        "colab_type": "text"
      },
      "source": [
        "#### Translate test set\n",
        "\n",
        "(OpenNMT is not very efficient - this takes about 45 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7uRFNfmcSfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not Path('pcfglet/pred_transformer_run_1.txt').is_file():\n",
        "  !python OpenNMT-py/translate.py \\\n",
        "  -model \"$BEST_TRANSFORMER_RUN_1\" \\\n",
        "  -src pcfglet/src-test.txt \\\n",
        "  -tgt pcfglet/tgt-test.txt \\\n",
        "  -output pcfglet/pred_transformer_run_1.txt\n",
        "\n",
        "if not Path('pcfglet/pred_transformer_run_2.txt').is_file():\n",
        "  !python OpenNMT-py/translate.py \\\n",
        "  -model \"$BEST_TRANSFORMER_RUN_2\" \\\n",
        "  -src pcfglet/src-test.txt \\\n",
        "  -tgt pcfglet/tgt-test.txt \\\n",
        "  -output pcfglet/pred_transformer_run_2.txt\n",
        "\n",
        "if not Path('pcfglet/pred_transformer_run_3.txt').is_file():\n",
        "  !python OpenNMT-py/translate.py \\\n",
        "  -model \"$BEST_TRANSFORMER_RUN_3\" \\\n",
        "  -src pcfglet/src-test.txt \\\n",
        "  -tgt pcfglet/tgt-test.txt \\\n",
        "  -output pcfglet/pred_transformer_run_3.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN7UJJqe-aGk",
        "colab_type": "text"
      },
      "source": [
        "#### Optional Checkpoint: persist predictions to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXttkPH3-Vp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r pcfglet/pred_transformer_* \"drive/My Drive/pcfglet/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL18ug7Bs7mI",
        "colab_type": "text"
      },
      "source": [
        "### Finalize Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avlhjnUVs-bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS = {\n",
        "  'lstms2s': {\n",
        "    1: BEST_LSTM_RUN_1,\n",
        "    2: BEST_LSTM_RUN_2,\n",
        "    3: BEST_LSTM_RUN_3\n",
        "  },\n",
        "  'transformer': {\n",
        "    1: BEST_TRANSFORMER_RUN_1,\n",
        "    2: BEST_TRANSFORMER_RUN_2,\n",
        "    3: BEST_TRANSFORMER_RUN_3\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IogY-71hGq5",
        "colab_type": "text"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5X_UwWiXrtt",
        "colab_type": "text"
      },
      "source": [
        "### Task Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTblg0XVYpuz",
        "colab_type": "text"
      },
      "source": [
        "#### Define code to calculate and display task accuracy by sequence feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pha1fqQfXt6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_task_accuracy_dataframe() -> pd.DataFrame:\n",
        "  frame = {\n",
        "    'length': [],\n",
        "    'depth': [],\n",
        "    'num_functions': [],\n",
        "    'accuracy': [],\n",
        "    'model_type': [],\n",
        "    'trial': []\n",
        "  }\n",
        "  accuracies = {\n",
        "    'lstms2s': {\n",
        "        1: np.zeros(len(TEST_SET)),\n",
        "        2: np.zeros(len(TEST_SET)),\n",
        "        3: np.zeros(len(TEST_SET))\n",
        "    },\n",
        "    'transformer': {\n",
        "        1: np.zeros(len(TEST_SET)),\n",
        "        2: np.zeros(len(TEST_SET)),\n",
        "        3: np.zeros(len(TEST_SET))\n",
        "    },\n",
        "  }\n",
        "  targets = list(map(str.rstrip, list(open(f'pcfglet/tgt-test.txt'))))\n",
        "  for model_type in ['lstms2s', 'transformer']:\n",
        "    for trial in range(1,4):\n",
        "      predictions = map(str.rstrip, list(open(f'pcfglet/pred_{model_type}_run_{trial}.txt')))\n",
        "      for i, (prediction, target) in enumerate(zip(predictions, targets)):\n",
        "        accuracies[model_type][trial][i] = float(prediction == target)\n",
        "  with tqdm(total=len(TEST_SET) * 2 * 3) as progress_bar:\n",
        "    for i, sequence_data in enumerate(TEST_SET.itertuples()):\n",
        "      for model_type in ['lstms2s', 'transformer']:\n",
        "        for trial in range(1,4):\n",
        "          frame['length'].append(sequence_data.length)\n",
        "          frame['depth'].append(sequence_data.depth)\n",
        "          frame['num_functions'].append(sequence_data.num_functions)\n",
        "          frame['accuracy'].append(accuracies[model_type][trial][i])\n",
        "          frame['model_type'].append(model_type)\n",
        "          frame['trial'].append(trial)\n",
        "          progress_bar.update(1)\n",
        "  df = pd.DataFrame(frame)\n",
        "  df.to_pickle('pcfglet/accuracy.pkl')\n",
        "  return df\n",
        "\n",
        "def plot_accuracy_by_dimension(accuracy_frame: pd.DataFrame, dimension: str, xlim: Tuple[int, int], xticks: List[int]) -> None:\n",
        "  plt.clf()\n",
        "  ax = sns.lineplot(x=dimension, y='accuracy', data=accuracy_frame, style='model_type')\n",
        "  ax.set_ylim((0,1))\n",
        "  ax.set_xlim(xlim)\n",
        "  ax.set_xticks(xticks)\n",
        "  ax.grid(True)\n",
        "  plt.savefig(f'pcfglet/task_accuracy_by_{dimension}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv6aDymSYzUo",
        "colab_type": "text"
      },
      "source": [
        "#### Build task accuracy data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIeper3TXzY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not Path('pcfglet/accuracy.pkl').is_file():\n",
        "  TASK_ACCURACY = build_task_accuracy_dataframe()\n",
        "else:\n",
        "  TASK_ACCURACY = pd.read_pickle('pcfglet/accuracy.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6XckbXqY3QW",
        "colab_type": "text"
      },
      "source": [
        "#### Calculate average task accuracy ± standard deviation across all trials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYX2aYS3Y9YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_accuracy_by_type = TASK_ACCURACY.groupby(['model_type', 'trial'])['accuracy'].mean()\n",
        "for model_type in ['lstms2s', 'transformer']:\n",
        "  mean = np.mean(mean_accuracy_by_type[model_type])\n",
        "  std = np.std(mean_accuracy_by_type[model_type])\n",
        "  print(f'Average task accuracy for {model_type}: {mean} ± {std}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsHM-SoXZABI",
        "colab_type": "text"
      },
      "source": [
        "#### Plot average task accuracy for each model type by the same features as Hupkes et al. 2019."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1oo-vA7byBr",
        "colab_type": "text"
      },
      "source": [
        "By sequence length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6S_yPGvZHBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not Path('pcfglet/task_accuracy_by_length.png').is_file():\n",
        "  plot_accuracy_by_dimension(TASK_ACCURACY, 'length', (5,50), list(range(5,51,5)))\n",
        "else:\n",
        "  display(Image('pcfglet/task_accuracy_by_length.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2FMRriFb00S",
        "colab_type": "text"
      },
      "source": [
        "By sequence depth:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txLxUpS4b2NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not Path('pcfglet/task_accuracy_by_depth.png').is_file():\n",
        "  plot_accuracy_by_dimension(TASK_ACCURACY, 'depth', (1,13), list(range(1,14,3)))\n",
        "else:\n",
        "  display(Image('pcfglet/task_accuracy_by_depth.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ehN1PW8b3Q5",
        "colab_type": "text"
      },
      "source": [
        "By number of functions in the sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guQmtDmeb5Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not Path('pcfglet/task_accuracy_by_num_functions.png').is_file():\n",
        "  plot_accuracy_by_dimension(TASK_ACCURACY, 'num_functions', (1,15), list(range(1,16,3)))\n",
        "else:\n",
        "  display(Image('pcfglet/task_accuracy_by_num_functions.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dgsZDJSbAhr",
        "colab_type": "text"
      },
      "source": [
        "#### Optional Checkpoint: persist task accuracy dataframe and plots to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zPvs4rdbEVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r pcfglet/accuracy.pkl \"drive/My Drive/pcfglet/\"\n",
        "# !cp -r pcfglet/task_accuracy*.png \"drive/My Drive/pcfglet/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Frbes7rhKxc",
        "colab_type": "text"
      },
      "source": [
        "### Localism\n",
        "\n",
        "We test the localism of trained models similarly to ([Hupkes et al. 2019](https://arxiv.org/abs/1908.08351)) by unrolling computationsand comparing  model’s  successive local predictions to their global ones.  The final prediction is **consistent** if it matches the global prediction, and **accurate** if it matches the target.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T81uQGh5Tj1_",
        "colab_type": "text"
      },
      "source": [
        "#### Define code to predict the output of an arbitrary command\n",
        "\n",
        "We need to be able to predict the output of any command in order to examine model performance on individual functions when unrolling computations. One possible solution is to transform a string command into a parse tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJgdR2y4orR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a parsed sequence will either be an empty token or list of integers\n",
        "ParsedSequence = Union[str, List[int]]\n",
        "\n",
        "def _try_to_parse_int(string: str) -> Union[int, str]:\n",
        "  '''Cast a string to an integer if possible'''\n",
        "  try:\n",
        "    val = int(string)\n",
        "    return val\n",
        "  except ValueError:\n",
        "    return string\n",
        "\n",
        "def is_valid_token(token: Any) -> bool:\n",
        "  '''Check if a given string is a valid token in PCFG-LET'''\n",
        "  is_string = isinstance(token, str)\n",
        "  is_empty_token = token == 'E'\n",
        "  is_comma = token == ','\n",
        "  is_numerical_character = is_string and token.isdigit()\n",
        "  is_pcfg_function_name = is_string and (hasattr(UnaryFunctions, token) or hasattr(BinaryFunctions, token))\n",
        "  return any([is_empty_token, is_comma, is_numerical_character, is_pcfg_function_name])\n",
        "\n",
        "def is_valid_parsed_token(parsed_token: Any) -> bool:\n",
        "  '''Check if a given PCFG-LET token has been parsed correctly'''\n",
        "  is_empty_token = parsed_token == 'E'\n",
        "  is_comma = parsed_token == ','\n",
        "  is_numerical_list = isinstance(parsed_token, list) and all([isinstance(val, int) for val in parsed_token])\n",
        "  is_pcfg_function = is_valid_function(parsed_token)\n",
        "  return any([is_empty_token, is_comma, is_numerical_list, is_pcfg_function])\n",
        "\n",
        "def is_valid_unary_function(token: Callable) -> bool:\n",
        "  '''Check if a parsed PCFG-LET token is a Unary function'''\n",
        "  return callable(token) and hasattr(UnaryFunctions, token.__name__)\n",
        "\n",
        "def is_valid_binary_function(token: Callable) -> bool:\n",
        "  '''Check if a parsed PCFG-LET token is a Binary function'''\n",
        "  return callable(token) and hasattr(BinaryFunctions, token.__name__)\n",
        "\n",
        "def is_valid_function(token: Callable) -> bool:\n",
        "  '''Check if a parsed PCFG-LET token is a Unary or Binary unction'''\n",
        "  return is_valid_unary_function(token) or is_valid_binary_function(token)\n",
        "\n",
        "def is_valid_pcfg_function_argument(token: ParsedSequence) -> bool:\n",
        "  '''Check if a parsed PCFG-LET token is a valid argument to a Unary or Binary function'''\n",
        "  is_empty_token = token == 'E'\n",
        "  is_numerical_list = isinstance(token, list) and all([isinstance(val, int) for val in token])\n",
        "  return is_empty_token or is_numerical_list\n",
        "\n",
        "def _command_to_parsed_stack(command: str) -> List[ParsedToken]:\n",
        "  '''Turn a string command into a parsed stack'''\n",
        "  stack = []\n",
        "  tokens = command.split(' ')\n",
        "  assert all(list(map(is_valid_token, tokens)))\n",
        "  parsed_tokens = list(map(_try_to_parse_int, tokens))\n",
        "  current_numerical_sequence = []\n",
        "  for parsed_token in parsed_tokens:\n",
        "    if isinstance(parsed_token, int):\n",
        "      current_numerical_sequence.append(parsed_token)\n",
        "    else:\n",
        "      if current_numerical_sequence:\n",
        "        stack.append(current_numerical_sequence)\n",
        "        current_numerical_sequence = []\n",
        "      if hasattr(BinaryFunctions, parsed_token):\n",
        "        stack.append(getattr(BinaryFunctions, parsed_token))\n",
        "      elif hasattr(UnaryFunctions, parsed_token):\n",
        "        stack.append(getattr(UnaryFunctions, parsed_token))\n",
        "      else:\n",
        "        stack.append(parsed_token)\n",
        "  if current_numerical_sequence:\n",
        "    stack.append(current_numerical_sequence)\n",
        "  stack = list(reversed(stack))\n",
        "  assert all(list(map(is_valid_parsed_token, stack)))\n",
        "  return stack\n",
        "\n",
        "def _stack_to_parse_tree(stack: List[ParsedToken]) -> treelib.Tree:\n",
        "  '''Turn a parsed stack into a parse tree'''\n",
        "  tree = treelib.Tree()\n",
        "  current_node = None # pointer for traversing the tree during construction\n",
        "  while stack:\n",
        "    val = stack.pop()\n",
        "    tag = val.__name__ if callable(val) else str(val)\n",
        "    # case 1: create root\n",
        "    if not tree:\n",
        "      current_node = tree.create_node(tag=tag, identifier='root', data=val)\n",
        "      continue\n",
        "    # case 2: find where to insert second argument of a binary function\n",
        "    if val == ',':\n",
        "      while True:\n",
        "        current_node = tree.parent(current_node.identifier)\n",
        "        if current_node is None:\n",
        "          raise ValueError('No matching binary function for second argument')\n",
        "        children = tree.children(current_node.identifier)\n",
        "        if len(children) == 1 and callable(current_node.data) and hasattr(BinaryFunctions, current_node.data.__name__):\n",
        "          break\n",
        "    # case 3: insert node\n",
        "    else:\n",
        "      children = tree.children(current_node.identifier)\n",
        "      # add a direction stem to the node ID, since treelib does not maintain insertion order\n",
        "      node_id = f'{str(uuid.uuid4())}|{\"RIGHT\" if children else \"LEFT\"}' \n",
        "      current_node = tree.create_node(tag=tag, identifier=node_id, data=val, parent=current_node.identifier)\n",
        "  return tree\n",
        "\n",
        "def _calculate_output_from_parse_tree(parse_tree: treelib.Tree) -> ParsedSequence:\n",
        "  '''Condense a parse tree into the final command output'''\n",
        "  current_node = parse_tree.get_node('root')\n",
        "  tree = treelib.Tree(tree=parse_tree, deep=True)\n",
        "  LEFT = '|LEFT'\n",
        "  RIGHT = '|RIGHT'\n",
        "  next_direction = LEFT\n",
        "  while tree.depth() > 0:\n",
        "\n",
        "    if not is_valid_parsed_token(current_node.data):\n",
        "      raise ValueError(f'treelib.Tree could not be parsed. Current node data: {current_node.data}')\n",
        "\n",
        "    children = tree.children(current_node.identifier)\n",
        "    if len(children) == 0:\n",
        "      next_direction = LEFT if next_direction == RIGHT else RIGHT\n",
        "      current_node = tree.parent(current_node.identifier)\n",
        "    else:\n",
        "      children_data = [child.data for child in children]\n",
        "      should_condense = len(children) > 0 and all([is_valid_pcfg_function_argument(child) for child in children_data])\n",
        "      if should_condense:\n",
        "        if len(children) == 2 and is_valid_binary_function(current_node.data):\n",
        "          left_child = next(child.data for child in children if LEFT in child.identifier)\n",
        "          right_child = next(child.data for child in children if RIGHT in child.identifier)\n",
        "          result = current_node.data(left_child, right_child)\n",
        "        elif len(children) == 1 and is_valid_unary_function(current_node.data):\n",
        "          result = current_node.data(children_data[0])\n",
        "        else:\n",
        "          raise ValueError('treelib.Tree could not be condensed. Phrase does not meet rules of the PCFG LET task')\n",
        "        tree.update_node(current_node.identifier, data=result, tag=str(result))\n",
        "        current_node = tree.parent(current_node.identifier)\n",
        "        for child in children:\n",
        "          tree.remove_node(child.identifier)\n",
        "      else:\n",
        "        try:\n",
        "          child_id = next(child.identifier for child in children if next_direction in child.identifier)\n",
        "        except StopIteration:\n",
        "          raise ValueError('treelib.Tree could not be condensed. Phrase does not meet rules of the PCFG LET task')\n",
        "        current_node = tree.get_node(child_id)\n",
        "        next_direction = LEFT\n",
        "  return tree.get_node('root').data\n",
        "\n",
        "def predict_command(command: str):\n",
        "  '''Predict the output of any given PCFG-LET string command'''\n",
        "  stack = _command_to_parsed_stack(command)\n",
        "  parse_tree = _stack_to_parse_tree(stack)\n",
        "  output = _calculate_output_from_parse_tree(parse_tree)\n",
        "  return list_to_string(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Eg9ZyiVBge",
        "colab_type": "text"
      },
      "source": [
        "#### Define code to perform unrolled computations and produce graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMQiUDmWhMYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_one(translator: onmt.translate.Translator, source_sentence: str) -> List[str]:\n",
        "  '''Translate a source sentence using OpenNMT'''\n",
        "  prediction = translator.translate(src=[source_sentence], batch_size=1)\n",
        "  # Looks like ([[tensor(-0.0005)]], [['21 5 7']])\n",
        "  return prediction[1][0][0].split(' ')\n",
        "\n",
        "def process_unrolled(steps, translator) -> Tuple[str, List[Tuple[str, str]]]:\n",
        "  '''Process a series of unrolled steps with wildcards'''\n",
        "  pairs = []\n",
        "  collect_outcomes = dict()\n",
        "  for step in steps:\n",
        "    source, target = step.split('|')\n",
        "    source_tokens = source.split(' ')\n",
        "    for i, token in enumerate(source_tokens):\n",
        "      if '*' in token:\n",
        "        source_tokens[i] = collect_outcomes[token]\n",
        "      source_tokens_flattened = []\n",
        "      for token in source_tokens:\n",
        "        if type(token) != list:\n",
        "          source_tokens_flattened.append(token)\n",
        "        else:\n",
        "          source_tokens_flattened.extend(token)\n",
        "      source_tokens = source_tokens_flattened\n",
        "    source_command = list_to_string(source_tokens)\n",
        "    prediction = translate_one(translator, source_tokens)\n",
        "    str_prediction = list_to_string(prediction)\n",
        "    pairs.append((source_command, str_prediction))\n",
        "    if '*' in target:\n",
        "      collect_outcomes[target] = str_prediction\n",
        "  return str_prediction, pairs\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "onmt.opts.translate_opts(parser)\n",
        "\n",
        "def load_localism_frames() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "  '''Load the localism frames from the persistence folder'''\n",
        "  return pd.read_pickle('pcfglet/localism_sequence.pkl'), pd.read_pickle('pcfglet/localism_function.pkl')\n",
        "\n",
        "def build_localism_dataframes() -> pd.DataFrame:\n",
        "  '''Store the results of unrolled computations and individual function performance into two separate dataframes'''\n",
        "  sequence_localism_frame = {\n",
        "    'trial': [],\n",
        "    'model_type': [],\n",
        "    'command': [],\n",
        "    'consistency': [],\n",
        "    'accuracy': [],\n",
        "    'input_length': [],\n",
        "    'target_length': [],\n",
        "    'depth': []\n",
        "  }\n",
        "  function_localism_frame = {\n",
        "    'trial': [],\n",
        "    'model_type': [],\n",
        "    'function': [],\n",
        "    'accuracy': [],\n",
        "    'target': []\n",
        "  }\n",
        "  with tqdm(total=2*3*len(TEST_SET)) as progress_bar:\n",
        "    for model_type in MODELS.keys():\n",
        "      for trial, model in MODELS[model_type].items():\n",
        "        opt = parser.parse_args(['-model', model, '-src', 'pcfglet/src-test.txt'])\n",
        "        translator = onmt.translate.translator.build_translator(opt, report_score=True, logger=logging.getLogger('onmt'))\n",
        "        predictions = map(str.rstrip, list(open(f'pcfglet/pred_{model_type}_run_{trial}.txt')))\n",
        "        for i, (sequence_data, prediction) in enumerate(zip(TEST_SET.itertuples(), predictions)):\n",
        "          unrolled_predicted, pairs = process_unrolled(sequence_data.unrolled_steps, translator)\n",
        "\n",
        "          consistent = float(unrolled_predicted == prediction)\n",
        "          correct = float(unrolled_predicted == sequence_data.target)\n",
        "\n",
        "          sequence_localism_frame['trial'].append(trial)\n",
        "          sequence_localism_frame['model_type'].append(model_type)\n",
        "          sequence_localism_frame['command'].append(sequence_data.command)\n",
        "          sequence_localism_frame['consistency'].append(consistent)\n",
        "          sequence_localism_frame['accuracy'].append(correct)\n",
        "          sequence_localism_frame['input_length'].append(sequence_data.length)\n",
        "          sequence_localism_frame['target_length'].append(len(sequence_data.target.split(' ')))\n",
        "          sequence_localism_frame['depth'].append(len(pairs))\n",
        "\n",
        "          for local_command, local_prediction in pairs:\n",
        "            local_tokens = local_command.split(' ')\n",
        "            function = local_tokens[0]\n",
        "\n",
        "            # if the model made no prediction, consider the output incorrect\n",
        "            if '' in local_tokens:\n",
        "              locally_correct = 0\n",
        "            else:\n",
        "              correct_output = predict_command(local_command)\n",
        "              locally_correct = float(local_prediction == correct_output)\n",
        "\n",
        "            function_localism_frame['trial'].append(trial)\n",
        "            function_localism_frame['model_type'].append(model_type)\n",
        "            function_localism_frame['function'].append(function)\n",
        "            function_localism_frame['accuracy'].append(locally_correct)\n",
        "            function_localism_frame['target'].append(correct_output)\n",
        "\n",
        "          progress_bar.update(1)\n",
        "  sequence_frame = pd.DataFrame(sequence_localism_frame)\n",
        "  sequence_frame.to_pickle('pcfglet/localism_sequence.pkl')\n",
        "  function_frame = pd.DataFrame(function_localism_frame)\n",
        "  function_frame.to_pickle('pcfglet/localism_function.pkl')\n",
        "\n",
        "  return sequence_frame, function_frame\n",
        "\n",
        "def print_localism_scores_for_frame(frame: pd.DataFrame, after_depth: int = None) -> None:\n",
        "  '''Print average localism consistency and performance for sequences deeper than the given depth'''\n",
        "  if after_depth:\n",
        "    frame = frame.loc[frame['depth'] > after_depth]\n",
        "  print(f'Localism results for depth > {after_depth or 0}')\n",
        "  mean_consistency_by_type = frame.groupby(['model_type', 'trial'])['consistency'].mean()\n",
        "  mean_performance_by_type = frame.groupby(['model_type', 'trial'])['accuracy'].mean()\n",
        "  for model_type in ['lstms2s', 'transformer']:\n",
        "    mean_consistency = np.mean(mean_consistency_by_type[model_type])\n",
        "    std_consistency = np.std(mean_consistency_by_type[model_type])\n",
        "    mean_performance = np.mean(mean_performance_by_type[model_type])\n",
        "    std_performance = np.std(mean_performance_by_type[model_type])\n",
        "    print(f'Average Localism consistency for {model_type}: {mean_consistency} ± {std_consistency}')\n",
        "    print(f'Average Localism performance for {model_type}: {mean_performance} ± {std_performance}')\n",
        "\n",
        "def plot_localism_lines_by_model_type(frame: pd.DataFrame, x: str, y: str, xlim: Tuple[int, int], xticks: List[int], ylim: Tuple[int, int] = (0,1), yticks: List[int] = None) -> None:\n",
        "  '''Generate save a localism score (consistency or accuracy) by dimension (input_length, depth, etc...)'''\n",
        "  plt.clf()\n",
        "  ax = sns.lineplot(x=x, y=y, data=frame, style='model_type')\n",
        "  ax.set_ylim(ylim)\n",
        "  ax.set_xlim(xlim)\n",
        "  ax.set_xticks(xticks)\n",
        "  ax.grid(True)\n",
        "  plt.savefig(f'pcfglet/localism_{y}_by_{x}.png')\n",
        "\n",
        "def plot_performance_by_function(frame, non_empty_targets: bool = False):\n",
        "  '''Plot performance per function (optionally for functions where the target is not empty)'''\n",
        "  plt.clf()\n",
        "  TO_GRAPH = frame\n",
        "  TO_GRAPH = TO_GRAPH.sort_values('function', ascending=False)\n",
        "  if non_empty_targets:\n",
        "    TO_GRAPH = TO_GRAPH.loc[TO_GRAPH['target'] != 'E']\n",
        "  count_map = TO_GRAPH.loc[(TO_GRAPH[\"model_type\"] =='lstms2s') & (TO_GRAPH[\"trial\"] == 1)].groupby('function').count()['trial'].to_dict()\n",
        "  f, ax = plt.subplots(figsize=(10, 6))\n",
        "  sns.barplot(x='accuracy', y='function', data=TO_GRAPH, hue='model_type')\n",
        "  ax.set_xlim((0,1))\n",
        "  ax.set_xticks([0,0.2,0.4,0.6,0.8, 1.0])\n",
        "  ax.set_yticklabels([f'{key} ({count_map[key]})' for key in sorted(count_map.keys(), reverse=True)])\n",
        "  renderer = tight_layout.get_renderer(f)\n",
        "  inset_tight_bbox = ax.get_tightbbox(renderer)\n",
        "  extent = inset_tight_bbox.transformed(f.dpi_scale_trans.inverted())\n",
        "  plt.savefig(f'pcfglet/localism_performance_by_function{\"_non_empty\" if non_empty_targets else \"\"}.png', bbox_inches=extent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPEx6qK_zv22",
        "colab_type": "text"
      },
      "source": [
        "#### Build localism dataframes\n",
        "This will take about 1.5-2 hours (OpenNMT translation is slow :( )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcO4RYAx2gdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "localism_files = [\n",
        "  'pcfglet/localism_sequence.pkl',\n",
        "  'pcfglet/localism_function.pkl'\n",
        "]\n",
        "\n",
        "\n",
        "if all([Path(f).is_file() for f in localism_files]):\n",
        "  print('Localism frames already exist. Loading from disk.')\n",
        "  SEQUENCE_LOCALISM, PERFORMANCE_BY_FUNCTION = load_localism_frames()\n",
        "else:\n",
        "  SEQUENCE_LOCALISM, PERFORMANCE_BY_FUNCTION = build_localism_dataframes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKPIF1xOg9bW",
        "colab_type": "text"
      },
      "source": [
        "#### Display results of Localism tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rugEPM9UWK8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,4):\n",
        "  print_localism_scores_for_frame(SEQUENCE_LOCALISM, after_depth=i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdT54Eb3hIBh",
        "colab_type": "text"
      },
      "source": [
        "#### Plot consistency score by input length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJAZ2_X_VNmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_localism_lines_by_model_type(SEQUENCE_LOCALISM, 'input_length', 'consistency', (1,50), [1] + list(range(5,51,5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWdEgPJRhLzZ",
        "colab_type": "text"
      },
      "source": [
        "#### Plot consistency score by target length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ooTI_I1O6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_localism_lines_by_model_type(SEQUENCE_LOCALISM, 'target_length', 'consistency', (1,50), [1] + list(range(5,51,5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAJIQ5-hP99",
        "colab_type": "text"
      },
      "source": [
        "#### Plot consistency score by sequence depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3IrpGHYhWSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_localism_lines_by_model_type(SEQUENCE_LOCALISM, 'depth', 'consistency', (1,10), list(range(1,11)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G500LDzphccV",
        "colab_type": "text"
      },
      "source": [
        "#### Plot localism accuracy by input length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zRxSFNAvzH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_localism_lines_by_model_type(SEQUENCE_LOCALISM, 'input_length', 'accuracy', (1,50), [1] + list(range(5,51,5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgO1HRd2hm72",
        "colab_type": "text"
      },
      "source": [
        "#### Plot localism accuracy by target length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcqkWf2O194t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_localism_lines_by_model_type(SEQUENCE_LOCALISM, 'target_length', 'accuracy', (1,50), [1] + list(range(5,51,5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXzUwvy5hpq6",
        "colab_type": "text"
      },
      "source": [
        "#### Plot localism accuracy by sequence depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OLRjJ9fzDcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_localism_lines_by_model_type(SEQUENCE_LOCALISM, 'depth', 'accuracy', (1,5), [1,2,3,4,5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP7zRKINhtAU",
        "colab_type": "text"
      },
      "source": [
        "#### Plot performance by function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytooAKkR1aUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_performance_by_function(PERFORMANCE_BY_FUNCTION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lw8gXp8hw7L",
        "colab_type": "text"
      },
      "source": [
        "#### Plot performance by function where the target is not an empty token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M15XoYT_h4vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_performance_by_function(PERFORMANCE_BY_FUNCTION, non_empty_targets=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7Acuve0gZGD",
        "colab_type": "text"
      },
      "source": [
        "#### Optional Checkpoint: persist localism dataframes and plots to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mSuK8qk26_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r pcfglet/localism*.pkl \"drive/My Drive/pcfglet/\"\n",
        "# !cp -r pcfglet/localism*.png \"drive/My Drive/pcfglet/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORKx0CjyiQF2",
        "colab_type": "text"
      },
      "source": [
        "#### Additional examination into poor model performance on certain functions\n",
        "\n",
        "Check how many primitive (the only function in the sequence) instances of `intersection` and `remove_unique` are in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neqyjru8c-_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_SET.loc[(TRAIN_SET['command'].str.contains('intersection')) & (TRAIN_SET['target'] != 'E') & (TRAIN_SET['num_functions'] == 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yh9929X0fYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_SET.loc[(TRAIN_SET['command'].str.contains('remove_unique')) & (TRAIN_SET['target'] != 'E') & (TRAIN_SET['num_functions'] == 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQHqkh17E1kV",
        "colab_type": "text"
      },
      "source": [
        "### Systematicity\n",
        "\n",
        "See the separate [notebook](https://colab.research.google.com/drive/1T_wjcRu9625N9mDmDn6oDBkJFRl542gp).\n",
        "\n",
        "Note: please ensure you have the folder titled 'Systematicity' containing the train, test and validation data and predictions saved in the root of your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgvDOzaOpupq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}